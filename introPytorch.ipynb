{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWhoATb0MwPN45l+htmeQ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmansoura/ai-engineer-journey/blob/main/introPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UOxvTA31w4bC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = [1,2,3,4]\n",
        "mylti_dim_list = [[1,2,3,4], [5,6,7,8]]\n",
        "print(my_list)\n",
        "print(mylti_dim_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyqMjB3sxnQv",
        "outputId": "d201efb9-c4b2-4467-813f-00026b0c57e6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4]\n",
            "[[1, 2, 3, 4], [5, 6, 7, 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "my_array = np.random.rand(3,4)\n",
        "print(my_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2BzOk0k1Rnp",
        "outputId": "81cc3367-a705-42bc-88c9-5b28be93c540"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.57272909 0.1051838  0.61971858 0.38428644]\n",
            " [0.23982703 0.23525556 0.80641933 0.64293024]\n",
            " [0.19484654 0.71312655 0.48570469 0.86052963]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2d = torch.rand(3,4)\n",
        "tensor_2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAjsgiTh14Hl",
        "outputId": "15cb40b2-46d3-4575-db3b-708f690d8ef9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7461, 0.7258, 0.7717, 0.2922],\n",
              "        [0.5406, 0.2661, 0.9481, 0.3287],\n",
              "        [0.4065, 0.5712, 0.6704, 0.9994]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = torch.zeros(2,3,4)\n",
        "tensor_3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ekOb6e2Vjx",
        "outputId": "6a051c20-8b53-42fb-bbeb-0358d7ab44b0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2937c2d2"
      },
      "source": [
        "# Task\n",
        "My task is to write and execute Python code using PyTorch to demonstrate the creation, manipulation, and fundamental operations of Tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00eaca65"
      },
      "source": [
        "## Introduction to PyTorch and Tensors\n",
        "\n",
        "### Subtask:\n",
        "Understand what PyTorch is, its advantages, and the fundamental concept of Tensors. We will cover creating, manipulating, and performing operations on tensors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9c2fd48"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step in understanding PyTorch and Tensors is to import the necessary library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3ad60c",
        "outputId": "35f38fec-205a-4e3b-ac7e-21f454552b6e"
      },
      "source": [
        "import torch\n",
        "print(\"PyTorch imported successfully.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7139c989"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that PyTorch is imported, the next step is to create various types of tensors, starting with creating a tensor from a Python list or NumPy array, as specified in instruction 2a.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01ca8b63",
        "outputId": "3c217fef-03b3-43d1-b406-2c501998d0a6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# From a Python list\n",
        "list_data = [[1, 2, 3], [4, 5, 6]]\n",
        "tensor_from_list = torch.tensor(list_data)\n",
        "print(\"Tensor from list:\\n\", tensor_from_list)\n",
        "\n",
        "# From a NumPy array\n",
        "numpy_array_data = np.array([[7, 8], [9, 10]])\n",
        "tensor_from_numpy = torch.from_numpy(numpy_array_data)\n",
        "print(\"\\nTensor from NumPy array:\\n\", tensor_from_numpy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor from list:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Tensor from NumPy array:\n",
            " tensor([[ 7,  8],\n",
            "        [ 9, 10]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaf69050"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, the next step is to create tensors using `torch.empty()`, `torch.zeros()`, and `torch.ones()` with specified shapes, as outlined in instruction 2b.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c64d90",
        "outputId": "1fa22636-c167-4146-91aa-e4da6abe308b"
      },
      "source": [
        "empty_tensor = torch.empty(2, 3)\n",
        "print(\"Empty Tensor:\\n\", empty_tensor)\n",
        "\n",
        "zeros_tensor = torch.zeros(3, 4)\n",
        "print(\"\\nZeros Tensor:\\n\", zeros_tensor)\n",
        "\n",
        "ones_tensor = torch.ones(2, 2)\n",
        "print(\"\\nOnes Tensor:\\n\", ones_tensor)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty Tensor:\n",
            " tensor([[6.1963e-04, 6.7333e+22, 2.7622e+29],\n",
            "        [4.3219e+27, 4.3055e+21, 1.8060e+28]])\n",
            "\n",
            "Zeros Tensor:\n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "\n",
            "Ones Tensor:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e027a48"
      },
      "source": [
        "**Reasoning**:\n",
        "Continuing with instruction 2c, the next step is to create random tensors using `torch.rand()` for uniform distribution and `torch.randn()` for normal distribution with specified shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6a72c918",
        "outputId": "0e423beb-1cbe-424e-ca15-a52e4e26b902"
      },
      "source": [
        "random_uniform_tensor = torch.rand(2, 3)\n",
        "print(\"Random Uniform Tensor (torch.rand):\n",
        "\", random_uniform_tensor)\n",
        "\n",
        "random_normal_tensor = torch.randn(3, 2)\n",
        "print(\"\\nRandom Normal Tensor (torch.randn):\n",
        "\", random_normal_tensor)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 2) (ipython-input-2131514353.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2131514353.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(\"Random Uniform Tensor (torch.rand):\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79a8bf3f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to an unterminated string literal in the print statements. I will fix the print statements by correctly closing the string literals and adding the newline character.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6fee594",
        "outputId": "8c0eab8b-3f6c-4abb-96d3-c8e9bb3f4412"
      },
      "source": [
        "random_uniform_tensor = torch.rand(2, 3)\n",
        "print(\"Random Uniform Tensor (torch.rand):\\n\", random_uniform_tensor)\n",
        "\n",
        "random_normal_tensor = torch.randn(3, 2)\n",
        "print(\"\\nRandom Normal Tensor (torch.randn):\\n\", random_normal_tensor)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Uniform Tensor (torch.rand):\n",
            " tensor([[0.7470, 0.2680, 0.5695],\n",
            "        [0.6122, 0.2704, 0.4371]])\n",
            "\n",
            "Random Normal Tensor (torch.randn):\n",
            " tensor([[-0.2243, -0.6883],\n",
            "        [-0.6111, -0.5849],\n",
            "        [ 0.2527,  0.0070]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3f93d5"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 3, the next step is to explore key tensor attributes such as `shape`, `dtype`, and `device` for some of the tensors created previously.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c3550f0",
        "outputId": "999f974c-c8fe-48cb-ba4e-f002c9356462"
      },
      "source": [
        "print(\"Attributes of tensor_from_list:\")\n",
        "print(\"Shape:\", tensor_from_list.shape)\n",
        "print(\"Data type:\", tensor_from_list.dtype)\n",
        "print(\"Device:\", tensor_from_list.device)\n",
        "\n",
        "print(\"\\nAttributes of random_uniform_tensor:\")\n",
        "print(\"Shape:\", random_uniform_tensor.shape)\n",
        "print(\"Data type:\", random_uniform_tensor.dtype)\n",
        "print(\"Device:\", random_uniform_tensor.device)\n",
        "\n",
        "# Check if CUDA is available and print device info\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nCUDA is available. Tensor will be moved to GPU.\")\n",
        "    cuda_device = torch.device(\"cuda\")\n",
        "    gpu_tensor = tensor_from_list.to(cuda_device)\n",
        "    print(\"Device of GPU tensor:\", gpu_tensor.device)\n",
        "else:\n",
        "    print(\"\\nCUDA is not available. Tensors are on CPU.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attributes of tensor_from_list:\n",
            "Shape: torch.Size([2, 3])\n",
            "Data type: torch.int64\n",
            "Device: cpu\n",
            "\n",
            "Attributes of random_uniform_tensor:\n",
            "Shape: torch.Size([2, 3])\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "\n",
            "CUDA is available. Tensor will be moved to GPU.\n",
            "Device of GPU tensor: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ab43632"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 4a, the next step is to demonstrate basic tensor manipulations by reshaping tensors using `.view()` and `.reshape()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22af2330",
        "outputId": "8c203cb9-5a1b-4fbe-91f1-6243f5d1e026"
      },
      "source": [
        "original_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"Original Tensor:\\n\", original_tensor)\n",
        "\n",
        "# Reshape using .view()\n",
        "reshaped_view_tensor = original_tensor.view(3, 2)\n",
        "print(\"\\nReshaped Tensor (view - 3x2):\\n\", reshaped_view_tensor)\n",
        "\n",
        "# Reshape using .reshape()\n",
        "reshaped_reshape_tensor = original_tensor.reshape(1, 6)\n",
        "print(\"\\nReshaped Tensor (reshape - 1x6):\\n\", reshaped_reshape_tensor)\n",
        "\n",
        "# Reshape using -1 for automatic size calculation\n",
        "reshaped_auto_tensor = original_tensor.reshape(-1, 3) # -1 means infer the size\n",
        "print(\"\\nReshaped Tensor (reshape - auto size):\\n\", reshaped_auto_tensor)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Reshaped Tensor (view - 3x2):\n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Reshaped Tensor (reshape - 1x6):\n",
            " tensor([[1, 2, 3, 4, 5, 6]])\n",
            "\n",
            "Reshaped Tensor (reshape - auto size):\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9425ccb4"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 4b, the next step is to perform slicing and indexing operations on tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a48049",
        "outputId": "2e863736-5c18-473e-a97d-97b2cb2f1bbe"
      },
      "source": [
        "my_tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print(\"Original Tensor:\\n\", my_tensor)\n",
        "\n",
        "# Access a single element\n",
        "print(\"\\nSingle element at [0, 1]:\", my_tensor[0, 1].item())\n",
        "\n",
        "# Slice a row\n",
        "print(\"\\nFirst row:\\n\", my_tensor[0, :])\n",
        "\n",
        "# Slice a column\n",
        "print(\"\\nSecond column:\\n\", my_tensor[:, 1])\n",
        "\n",
        "# Slice a sub-tensor\n",
        "print(\"\\nSub-tensor (rows 0-1, cols 1-2):\\n\", my_tensor[0:2, 1:3])\n",
        "\n",
        "# Using advanced indexing (list of indices)\n",
        "print(\"\\nElements at specific indices ([0,0], [1,2], [2,3]):\\n\", my_tensor[[0, 1, 2], [0, 2, 3]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "Single element at [0, 1]: 2\n",
            "\n",
            "First row:\n",
            " tensor([1, 2, 3, 4])\n",
            "\n",
            "Second column:\n",
            " tensor([ 2,  6, 10])\n",
            "\n",
            "Sub-tensor (rows 0-1, cols 1-2):\n",
            " tensor([[2, 3],\n",
            "        [6, 7]])\n",
            "\n",
            "Elements at specific indices ([0,0], [1,2], [2,3]):\n",
            " tensor([ 1,  7, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9b7e2c0"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 5a, the next step is to demonstrate element-wise arithmetic operations (addition, subtraction, multiplication, division) on tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1149720",
        "outputId": "145e2fa3-6058-4199-83e6-c63b046a5ca2"
      },
      "source": [
        "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "print(\"Tensor A:\\n\", tensor_a)\n",
        "print(\"Tensor B:\\n\", tensor_b)\n",
        "\n",
        "# Addition\n",
        "add_result = tensor_a + tensor_b\n",
        "print(\"\\nAddition (A + B):\\n\", add_result)\n",
        "\n",
        "# Subtraction\n",
        "sub_result = tensor_a - tensor_b\n",
        "print(\"\\nSubtraction (A - B):\\n\", sub_result)\n",
        "\n",
        "# Multiplication (element-wise)\n",
        "mul_result = tensor_a * tensor_b\n",
        "print(\"\\nElement-wise Multiplication (A * B):\\n\", mul_result)\n",
        "\n",
        "# Division (element-wise)\n",
        "div_result = tensor_a / tensor_b\n",
        "print(\"\\nElement-wise Division (A / B):\\n\", div_result)\n",
        "\n",
        "# Scalar multiplication\n",
        "scalar_mul_result = tensor_a * 2\n",
        "print(\"\\nScalar Multiplication (A * 2):\\n\", scalar_mul_result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Tensor B:\n",
            " tensor([[5, 6],\n",
            "        [7, 8]])\n",
            "\n",
            "Addition (A + B):\n",
            " tensor([[ 6,  8],\n",
            "        [10, 12]])\n",
            "\n",
            "Subtraction (A - B):\n",
            " tensor([[-4, -4],\n",
            "        [-4, -4]])\n",
            "\n",
            "Element-wise Multiplication (A * B):\n",
            " tensor([[ 5, 12],\n",
            "        [21, 32]])\n",
            "\n",
            "Element-wise Division (A / B):\n",
            " tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]])\n",
            "\n",
            "Scalar Multiplication (A * 2):\n",
            " tensor([[2, 4],\n",
            "        [6, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c39e518"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 5b, the next step is to demonstrate matrix multiplication using `torch.matmul()` or the `@` operator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f86c6595",
        "outputId": "fc83317f-8248-4d1f-c551-503ef61febf4"
      },
      "source": [
        "tensor_x = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor_y = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "print(\"Tensor X:\\n\", tensor_x)\n",
        "print(\"Tensor Y:\\n\", tensor_y)\n",
        "\n",
        "# Matrix multiplication using torch.matmul()\n",
        "matmul_result = torch.matmul(tensor_x, tensor_y)\n",
        "print(\"\\nMatrix Multiplication (torch.matmul):\\n\", matmul_result)\n",
        "\n",
        "# Matrix multiplication using @ operator\n",
        "operator_matmul_result = tensor_x @ tensor_y\n",
        "print(\"\\nMatrix Multiplication (@ operator):\\n\", operator_matmul_result)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor X:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Tensor Y:\n",
            " tensor([[5, 6],\n",
            "        [7, 8]])\n",
            "\n",
            "Matrix Multiplication (torch.matmul):\n",
            " tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "\n",
            "Matrix Multiplication (@ operator):\n",
            " tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "975210ed"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 5c, the next step is to demonstrate transposing a tensor using `.T` or `.transpose()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39f60c7",
        "outputId": "82f4817c-03a9-46e4-c5f6-ef4687da0556"
      },
      "source": [
        "original_tensor_t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"Original Tensor:\\n\", original_tensor_t)\n",
        "\n",
        "# Transpose using .T\n",
        "transposed_t = original_tensor_t.T\n",
        "print(\"\\nTransposed Tensor (.T):\\n\", transposed_t)\n",
        "\n",
        "# Transpose using .transpose()\n",
        "transposed_transpose = original_tensor_t.transpose(0, 1)\n",
        "print(\"\\nTransposed Tensor (.transpose(0, 1)):\\n\", transposed_transpose)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Transposed Tensor (.T):\n",
            " tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "\n",
            "Transposed Tensor (.transpose(0, 1)):\n",
            " tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a876bb2d"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 6, the next step is to demonstrate moving a tensor to a different device (specifically, the GPU if available) using the `.to()` method, as already partially demonstrated in instruction 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17be2996",
        "outputId": "95f12bbf-7b8b-42f3-a7eb-c5c9fe94025b"
      },
      "source": [
        "tensor_on_cpu = torch.tensor([[1, 2], [3, 4]])\n",
        "print(\"Tensor on CPU device:\", tensor_on_cpu.device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # Move tensor to GPU\n",
        "    tensor_on_gpu = tensor_on_cpu.to(\"cuda\")\n",
        "    print(\"Tensor moved to GPU device:\", tensor_on_gpu.device)\n",
        "else:\n",
        "    print(\"CUDA is not available. Tensor remains on CPU.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor on CPU device: cpu\n",
            "Tensor moved to GPU device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19e3f31"
      },
      "source": [
        "## Automatic Differentiation with Autograd\n",
        "\n",
        "### Subtask:\n",
        "Learn about PyTorch's `autograd` engine, which enables automatic computation of gradients. We will explore how it works and its importance in neural network training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74c8a9f9"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will start by creating a tensor `x` and setting `requires_grad=True`. This tells PyTorch to track all operations on this tensor for automatic gradient computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e7791f2"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will create a tensor `x` with `requires_grad=True` to signal PyTorch to track operations on it, and print the tensor to confirm its creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe3bfe5b",
        "outputId": "f100fac8-63c7-4bb1-86da-1b8efe0c30b7"
      },
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "print(\"Tensor x with requires_grad=True:\", x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor x with requires_grad=True: tensor([1., 2., 3.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78427ead"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 2, I will perform a series of operations on `x` to create a computational graph by defining `y = x**2` and `z = y.sum()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9895310",
        "outputId": "c593e448-4308-4049-a1fd-ff54b587d25a"
      },
      "source": [
        "y = x**2\n",
        "z = y.sum()\n",
        "print(\"Tensor y (x**2):\", y)\n",
        "print(\"Tensor z (y.sum()):\", z)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor y (x**2): tensor([1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "Tensor z (y.sum()): tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c5f0ffa"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the computational graph is set up (`z = (x**2).sum()`), as per instruction 3, I will compute the gradients of `z` with respect to `x` using the `.backward()` method on `z`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e077d447"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the computational graph is set up (`z = (x**2).sum()`), as per instruction 3, I will compute the gradients of `z` with respect to `x` using the `.backward()` method on `z`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2f202d",
        "outputId": "2ffcd4c9-9474-4f26-e48f-90556f950698"
      },
      "source": [
        "z.backward()\n",
        "print(\"Gradients computed successfully.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b32a481e"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will access the gradients of `x` using `x.grad` and print the result to inspect the computed gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b40f18a"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now access the computed gradients of `x` using `x.grad` and print them to verify the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5d88a6c",
        "outputId": "7ecf7f85-622f-47e7-9bec-c791c7d588f2"
      },
      "source": [
        "print(\"Gradients of x (x.grad):\", x.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of x (x.grad): tensor([2., 4., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c929d63"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now demonstrate how gradients accumulate. I will define a new operation `z2 = (x * 3).sum()`, perform a backward pass on `z2`, and then print `x.grad` again to observe the accumulation of gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e209fb37"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now define `z2 = (x * 3).sum()`, then call `z2.backward()` to accumulate gradients, and finally print `x.grad` to observe the accumulated gradients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5815e68c",
        "outputId": "75a5222b-6f93-42b7-dc78-7b0afadf35c3"
      },
      "source": [
        "z2 = (x * 3).sum()\n",
        "print(\"Tensor z2 ((x * 3).sum()):\", z2)\n",
        "z2.backward()\n",
        "print(\"Gradients of x after accumulating (x.grad):\", x.grad)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor z2 ((x * 3).sum()): tensor(18., grad_fn=<SumBackward0>)\n",
            "Gradients of x after accumulating (x.grad): tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75cba8f6"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 6, I will now reset the gradients of `x` using `x.grad.zero_()` and then confirm that they are indeed reset to zero by printing `x.grad`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03f6258d"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 6, I will now reset the gradients of `x` using `x.grad.zero_()` and then confirm that they are indeed reset to zero by printing `x.grad`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55cf3dfc",
        "outputId": "09dbd310-b878-41ad-a957-d3019e29bd87"
      },
      "source": [
        "x.grad.zero_()\n",
        "print(\"Gradients of x after reset (x.grad):\", x.grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of x after reset (x.grad): tensor([0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce330b62"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 7, I will now illustrate disabling gradient tracking using `with torch.no_grad():` block and demonstrate detaching a tensor from the computation graph using `.detach()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cc00734"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 7, I will now demonstrate disabling gradient tracking using `with torch.no_grad():` and detaching a tensor using `.detach()` and print the results to show their effect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "90582ac2",
        "outputId": "695b9abe-0d31-42f4-a03e-ff2a5d5eaa9f"
      },
      "source": [
        "x_no_grad = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
        "print(\"Original tensor for no_grad demo:\", x_no_grad)\n",
        "\n",
        "# Disabling gradient tracking with torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    y_no_grad = x_no_grad * 2\n",
        "    print(\"Tensor inside no_grad block (y_no_grad):\n",
        "\", y_no_grad)\n",
        "    print(\"y_no_grad.requires_grad:\", y_no_grad.requires_grad)\n",
        "\n",
        "# Detaching a tensor\n",
        "x_detach = torch.tensor([7.0, 8.0, 9.0], requires_grad=True)\n",
        "y_detach = x_detach * 2\n",
        "print(\"\\nOriginal tensor for detach demo:\", x_detach)\n",
        "print(\"Tensor y_detach (x_detach * 2):\n",
        "\", y_detach)\n",
        "print(\"y_detach.requires_grad:\", y_detach.requires_grad)\n",
        "\n",
        "detached_tensor = y_detach.detach()\n",
        "print(\"Detached tensor (detached_tensor):\n",
        "\", detached_tensor)\n",
        "print(\"detached_tensor.requires_grad:\", detached_tensor.requires_grad)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 7) (ipython-input-3449167404.py, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3449167404.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(\"Tensor inside no_grad block (y_no_grad):\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "528fe469"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to an unterminated string literal in multiple print statements. I will fix the print statements by correctly closing the string literals and ensuring that newline characters are correctly placed within the string or concatenated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf9aafb3",
        "outputId": "977ea285-e75d-4ad4-f6ac-e3b86c08a10c"
      },
      "source": [
        "x_no_grad = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
        "print(\"Original tensor for no_grad demo:\", x_no_grad)\n",
        "\n",
        "# Disabling gradient tracking with torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    y_no_grad = x_no_grad * 2\n",
        "    print(\"Tensor inside no_grad block (y_no_grad):\\n\", y_no_grad)\n",
        "    print(\"y_no_grad.requires_grad:\", y_no_grad.requires_grad)\n",
        "\n",
        "# Detaching a tensor\n",
        "x_detach = torch.tensor([7.0, 8.0, 9.0], requires_grad=True)\n",
        "y_detach = x_detach * 2\n",
        "print(\"\\nOriginal tensor for detach demo:\", x_detach)\n",
        "print(\"Tensor y_detach (x_detach * 2):\\n\", y_detach)\n",
        "print(\"y_detach.requires_grad:\", y_detach.requires_grad)\n",
        "\n",
        "detached_tensor = y_detach.detach()\n",
        "print(\"Detached tensor (detached_tensor):\\n\", detached_tensor)\n",
        "print(\"detached_tensor.requires_grad:\", detached_tensor.requires_grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor for no_grad demo: tensor([4., 5., 6.], requires_grad=True)\n",
            "Tensor inside no_grad block (y_no_grad):\n",
            " tensor([ 8., 10., 12.])\n",
            "y_no_grad.requires_grad: False\n",
            "\n",
            "Original tensor for detach demo: tensor([7., 8., 9.], requires_grad=True)\n",
            "Tensor y_detach (x_detach * 2):\n",
            " tensor([14., 16., 18.], grad_fn=<MulBackward0>)\n",
            "y_detach.requires_grad: True\n",
            "Detached tensor (detached_tensor):\n",
            " tensor([14., 16., 18.])\n",
            "detached_tensor.requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ad4df76"
      },
      "source": [
        "## Building Neural Networks with nn.Module\n",
        "\n",
        "### Subtask:\n",
        "Dive into `torch.nn` to define and build neural network architectures. This step will cover layers, activation functions, and assembling simple models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bce417a5"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will now define a simple neural network class using `torch.nn.Module`. This class will encapsulate a single linear layer, and I will implement the `__init__` method to define the layer and the `forward` method to specify the computation flow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "184f6f51"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will now define the `SimpleNN` class using `torch.nn.Module` with a single linear layer, implementing both the `__init__` and `forward` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db376746",
        "outputId": "0d9d0444-3efa-43e9-a259-4cf7a5621d96"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "print(\"SimpleNN class defined successfully.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN class defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f816a0e4"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now instantiate the `SimpleNN` model by creating an object of the class, specifying arbitrary `input_size` and `output_size` for demonstration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357146bf"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the reasoning in the previous markdown cell, I will now instantiate the `SimpleNN` model with a chosen `input_size` and `output_size` to create a working model instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef9365b7",
        "outputId": "b2e639ae-8ecb-4c06-9e47-b97b1f3b7983"
      },
      "source": [
        "input_size = 10\n",
        "output_size = 1\n",
        "model = SimpleNN(input_size, output_size)\n",
        "print(\"SimpleNN model instantiated successfully:\")\n",
        "print(model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN model instantiated successfully:\n",
            "SimpleNN(\n",
            "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9094556b"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, the model architecture has already been printed in the previous step, confirming the layers and parameters within the network. This completes instruction 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f19c2cd6"
      },
      "source": [
        "**Reasoning**:\n",
        "Following instruction 4, I will now demonstrate a forward pass through the instantiated model. This involves creating a dummy input tensor with the correct input shape and passing it through the model, then printing the shape of the output tensor to confirm the network's output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44d1b942"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now create a dummy input tensor with the appropriate input size and pass it through the `model` to perform a forward pass. I will then print the shape of the resulting output tensor to confirm the network's output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2e63505",
        "outputId": "8201cc14-b7ef-42ef-9448-08f62d9ec794"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Create a dummy input tensor (e.g., a batch of 1 with input_size features)\n",
        "dummy_input = torch.randn(1, input_size)\n",
        "print(\"Dummy input tensor shape:\", dummy_input.shape)\n",
        "\n",
        "# Perform a forward pass\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(\"\\nOutput tensor from forward pass:\", output)\n",
        "print(\"Output tensor shape:\", output.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy input tensor shape: torch.Size([1, 10])\n",
            "\n",
            "Output tensor from forward pass: tensor([[-0.9817]], grad_fn=<AddmmBackward0>)\n",
            "Output tensor shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a650bf39"
      },
      "source": [
        "## Defining Loss Functions and Optimizers\n",
        "\n",
        "### Subtask:\n",
        "Understand different types of loss functions (e.g., CrossEntropyLoss, MSELoss) and optimization algorithms (e.g., SGD, Adam) used to train neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26e2e5ef"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will import the necessary modules, `torch.nn` for loss functions and `torch.optim` for optimizers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2454f91b"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation, I will now import the `torch.nn` and `torch.optim` modules as instructed, which are essential for defining loss functions and optimizers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fc0d87d",
        "outputId": "91a1c96d-15b9-4729-f7e7-cf39e393720b"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"torch.nn and torch.optim modules imported successfully.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.nn and torch.optim modules imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69033897"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now instantiate a Mean Squared Error (MSE) loss function. This loss is commonly used for regression tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caa6f4ea"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 2, I will now instantiate the `nn.MSELoss` function, which is suitable for regression problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cee7fee",
        "outputId": "74cf2fa5-f81a-499e-dc00-72ece0bc1e16"
      },
      "source": [
        "mse_loss = nn.MSELoss()\n",
        "print(\"Mean Squared Error (MSE) loss function instantiated successfully.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) loss function instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baa2fa1c"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, I will now instantiate a Cross Entropy Loss function. This loss is typically used for classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4c77d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 3, I will now instantiate the `nn.CrossEntropyLoss` function, which is suitable for classification problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e064f3e",
        "outputId": "7bd2b710-f71d-4843-a5f2-1552680940f3"
      },
      "source": [
        "cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "print(\"Cross Entropy Loss function instantiated successfully.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss function instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4430156"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now instantiate an SGD (Stochastic Gradient Descent) optimizer. This optimizer is commonly used for training neural networks and requires the model's parameters and a learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dde1ba90"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 4, I will now instantiate the `optim.SGD` optimizer, passing the previously defined `model.parameters()` and a learning rate of 0.01.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c8ebf17",
        "outputId": "bad11e3c-6078-4941-db2c-8af625ad4b76"
      },
      "source": [
        "sgd_optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "print(\"SGD optimizer instantiated successfully.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD optimizer instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "434d9375"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now instantiate an Adam optimizer. This optimizer is also commonly used for training neural networks and requires the model's parameters and a learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "268148ee"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 5, I will now instantiate the `optim.Adam` optimizer, passing the previously defined `model.parameters()` and a learning rate of 0.001.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98fa68a",
        "outputId": "edd9b15a-fbc2-423a-8a2c-afd9c339e489"
      },
      "source": [
        "adam_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "print(\"Adam optimizer instantiated successfully.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam optimizer instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c91a53e"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Learn how to prepare data for training using `torch.utils.data.Dataset` and `DataLoader` for efficient batch processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffb93247"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will start by importing the necessary `Dataset` and `DataLoader` classes from `torch.utils.data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bae34b53"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will start by importing the necessary `Dataset` and `DataLoader` classes from `torch.utils.data`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40329cd",
        "outputId": "bac48ec8-e1a1-48a9-d45d-7a7f119f41ba"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"Dataset and DataLoader imported successfully.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and DataLoader imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a39074c"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now define a custom `MyDataset` class that inherits from `torch.utils.data.Dataset`. This class will include methods for initialization, length, and item retrieval to encapsulate dummy features and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9123df23"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now define the `MyDataset` class with `__init__`, `__len__`, and `__getitem__` methods to handle dummy features and labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab29fc34",
        "outputId": "5b75f787-12a5-451f-8b9a-e719cb6b8716"
      },
      "source": [
        "import torch\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, num_samples, num_features, num_labels=1):\n",
        "        self.features = torch.randn(num_samples, num_features)\n",
        "        self.labels = torch.randint(0, 2, (num_samples, num_labels)).float() # Binary labels for demonstration\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "print(\"MyDataset class defined successfully.\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDataset class defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e212828"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, I will now instantiate the `MyDataset` with specified `num_samples`, `num_features`, and `num_labels`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b04e796e"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation, I will now instantiate the `MyDataset` class with `num_samples=10`, `num_features=5`, and `num_labels=1` and print its length to verify its creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c28f3eea",
        "outputId": "db50b5c1-9e68-4d33-ac3a-a62d0a896b01"
      },
      "source": [
        "num_samples = 10\n",
        "num_features = 5\n",
        "num_labels = 1\n",
        "\n",
        "my_custom_dataset = MyDataset(num_samples, num_features, num_labels)\n",
        "print(f\"MyDataset instantiated successfully with {len(my_custom_dataset)} samples.\")\n",
        "print(f\"First feature sample shape: {my_custom_dataset[0][0].shape}\")\n",
        "print(f\"First label sample shape: {my_custom_dataset[0][1].shape}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDataset instantiated successfully with 10 samples.\n",
            "First feature sample shape: torch.Size([5])\n",
            "First label sample shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9bc9cd2"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now create a `DataLoader` instance, passing the `my_custom_dataset`, a `batch_size` of 2, and `shuffle=True` to enable batch processing and shuffling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12054ce7"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 4, I will now create a `DataLoader` instance using the `my_custom_dataset`, a `batch_size` of 2, and `shuffle=True` to prepare data for efficient batch processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aade62b",
        "outputId": "6a46c814-c1d5-4598-ec3e-cc81c66d6fa6"
      },
      "source": [
        "batch_size = 2\n",
        "my_dataloader = DataLoader(my_custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "print(f\"DataLoader instantiated successfully with batch size {batch_size}.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader instantiated successfully with batch size 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "471a3c36"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now iterate through the `DataLoader` using a `for` loop, printing the shape of the features and labels for each batch to demonstrate batching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b03ffe7"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the previous markdown explanation and instruction 5, I will now iterate through the `my_dataloader` using a `for` loop to print the shape of the features and labels for each batch, demonstrating how data is batched.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6958d7bd",
        "outputId": "b05d0da2-dc6f-4481-d518-89c87580fae3"
      },
      "source": [
        "for batch_idx, (features, labels) in enumerate(my_dataloader):\n",
        "    print(f\"Batch {batch_idx+1}:\")\n",
        "    print(f\"  Features shape: {features.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:\n",
            "  Features shape: torch.Size([2, 5])\n",
            "  Labels shape: torch.Size([2, 1])\n",
            "Batch 2:\n",
            "  Features shape: torch.Size([2, 5])\n",
            "  Labels shape: torch.Size([2, 1])\n",
            "Batch 3:\n",
            "  Features shape: torch.Size([2, 5])\n",
            "  Labels shape: torch.Size([2, 1])\n",
            "Batch 4:\n",
            "  Features shape: torch.Size([2, 5])\n",
            "  Labels shape: torch.Size([2, 1])\n",
            "Batch 5:\n",
            "  Features shape: torch.Size([2, 5])\n",
            "  Labels shape: torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96d5d1ad"
      },
      "source": [
        "## Implementing a Training Loop\n",
        "\n",
        "### Subtask:\n",
        "Construct a complete training loop, integrating model definition, data loading, loss calculation, backpropagation, and optimizer steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3e75b0"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will define a more complex neural network class, `NeuralNetwork`, that includes at least two linear layers and an activation function (`nn.ReLU`), and define its `__init__` and `forward` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6b90dbe",
        "outputId": "640e4181-3bed-475b-d730-821c79ded823"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "print(\"NeuralNetwork class defined successfully.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork class defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1c11934"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now instantiate the `NeuralNetwork` model, using `num_features` as the input size, `output_size` as 1, and a chosen `hidden_size`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d70762",
        "outputId": "72f4e685-ad0b-4455-c3b6-31a84c7cb6eb"
      },
      "source": [
        "hidden_size = 64\n",
        "model_nn = NeuralNetwork(num_features, hidden_size, num_labels)\n",
        "print(\"NeuralNetwork model instantiated successfully:\")\n",
        "print(model_nn)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork model instantiated successfully:\n",
            "NeuralNetwork(\n",
            "  (fc1): Linear(in_features=5, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec12af3a"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, I will now instantiate a suitable loss function for binary classification, `nn.BCEWithLogitsLoss()`, which is commonly used for this type of task as it combines a sigmoid activation and binary cross-entropy loss for numerical stability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da62beda",
        "outputId": "149d6ecb-44c4-4046-891e-c560b13c173d"
      },
      "source": [
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "print(\"nn.BCEWithLogitsLoss instantiated successfully.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nn.BCEWithLogitsLoss instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a815428"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now instantiate an Adam optimizer, passing the `model_nn`'s parameters and a learning rate of 0.001.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcef1715",
        "outputId": "f5422192-99ea-4f37-8a00-7c42af9cc68d"
      },
      "source": [
        "optimizer = optim.Adam(model_nn.parameters(), lr=0.001)\n",
        "print(\"Adam optimizer instantiated successfully.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam optimizer instantiated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c1b4daf"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now implement the complete training loop. This involves iterating through epochs, processing data in batches, performing forward passes, calculating loss, zeroing gradients, backpropagating, and updating model parameters, finally printing the loss for each epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7380c969",
        "outputId": "2667336b-baa2-42a5-e3b5-f202779ff81e"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "print(\"Starting training loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, (features, labels) in enumerate(my_dataloader):\n",
        "        # Forward pass\n",
        "        outputs = model_nn(features)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print loss for every epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(my_dataloader):.4f}')\n",
        "\n",
        "print(\"Training loop completed.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training loop...\n",
            "Epoch [1/10], Loss: 0.7053\n",
            "Epoch [2/10], Loss: 0.6948\n",
            "Epoch [3/10], Loss: 0.6875\n",
            "Epoch [4/10], Loss: 0.6781\n",
            "Epoch [5/10], Loss: 0.6712\n",
            "Epoch [6/10], Loss: 0.6642\n",
            "Epoch [7/10], Loss: 0.6571\n",
            "Epoch [8/10], Loss: 0.6523\n",
            "Epoch [9/10], Loss: 0.6449\n",
            "Epoch [10/10], Loss: 0.6397\n",
            "Training loop completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "847a1c0e"
      },
      "source": [
        "## Saving and Loading Models\n",
        "\n",
        "### Subtask:\n",
        "Learn how to save and load trained PyTorch models, allowing for model persistence and deployment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21676f4"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will save the state dictionary of the trained model (`model_nn`) to a file named 'model_state_dict.pth' using `torch.save()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71795e6f",
        "outputId": "e6854224-8a02-4bd3-9f21-bd88cd406522"
      },
      "source": [
        "torch.save(model_nn.state_dict(), 'model_state_dict.pth')\n",
        "print(\"Model state dictionary saved to 'model_state_dict.pth'.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state dictionary saved to 'model_state_dict.pth'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5590cd"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will create a new instance of the `NeuralNetwork` class (`loaded_model`) with the same architecture as the original model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba14a36f",
        "outputId": "bfd8bdf1-951b-460a-8303-50cafac9cbd9"
      },
      "source": [
        "loaded_model = NeuralNetwork(num_features, hidden_size, num_labels)\n",
        "print(\"New NeuralNetwork instance ('loaded_model') created successfully:\")\n",
        "print(loaded_model)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New NeuralNetwork instance ('loaded_model') created successfully:\n",
            "NeuralNetwork(\n",
            "  (fc1): Linear(in_features=5, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab6366ae"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, I will now load the saved state dictionary from 'model_state_dict.pth' into the `loaded_model` using `torch.load()` and `loaded_model.load_state_dict()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "003fb4be",
        "outputId": "7c92fe69-a8e1-4885-b739-68f6deb64cc5"
      },
      "source": [
        "loaded_model.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "print(\"State dictionary loaded into 'loaded_model' successfully.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State dictionary loaded into 'loaded_model' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ef64d85"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now set the `loaded_model` to evaluation mode using `loaded_model.eval()` to disable dropout and batch normalization for inference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4989c4d",
        "outputId": "2de23d1a-cff5-4d59-81bf-866fb0d61d8b"
      },
      "source": [
        "loaded_model.eval()\n",
        "print(\"Loaded model set to evaluation mode.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model set to evaluation mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2440c86a"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now create a dummy input tensor with a shape of `(1, num_features)` using `torch.randn()` to be used for forward passes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1647e688",
        "outputId": "a87d3caf-146e-480a-98e2-ebecc1f1b102"
      },
      "source": [
        "dummy_input = torch.randn(1, num_features)\n",
        "print(\"Dummy input tensor created successfully with shape:\", dummy_input.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy input tensor created successfully with shape: torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "941f339b"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 6 and 7, I will now perform a forward pass using both the original `model_nn` and the `loaded_model` with the `dummy_input`, and then print their outputs to verify that they produce similar results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3950767",
        "outputId": "8d37b0c0-315c-494a-af00-67aee7cdade4"
      },
      "source": [
        "model_nn.eval()\n",
        "with torch.no_grad():\n",
        "    original_model_output = model_nn(dummy_input)\n",
        "    loaded_model_output = loaded_model(dummy_input)\n",
        "\n",
        "print(\"Output from original model:\", original_model_output)\n",
        "print(\"Output from loaded model:\", loaded_model_output)\n",
        "\n",
        "# Verify if outputs are similar (e.g., using torch.allclose)\n",
        "if torch.allclose(original_model_output, loaded_model_output):\n",
        "    print(\"Outputs from original and loaded models are similar.\")\n",
        "else:\n",
        "    print(\"Outputs from original and loaded models are NOT similar.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from original model: tensor([[0.4020]])\n",
            "Output from loaded model: tensor([[0.4020]])\n",
            "Outputs from original and loaded models are similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf0d4ed"
      },
      "source": [
        "## Practical Example: Image Classification\n",
        "\n",
        "### Subtask:\n",
        "Apply all learned concepts to a hands-on project, such as building and training a basic image classifier on a public dataset like MNIST or FashionMNIST.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6810115a"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 1, I will start by importing all the necessary libraries for building and training an image classifier: `torch`, `torchvision`, `torch.nn`, and `torch.optim`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ce3b6d",
        "outputId": "e2a944b9-b40e-4ffe-a7c9-aa8846795e27"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"Necessary libraries imported successfully.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary libraries imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b4a2422"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 2, I will now define data transformations for the training and test datasets. This includes converting images to tensors and normalizing pixel values for both sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a699e083",
        "outputId": "5e79a698-d9ff-4d38-d005-6a44be4430ac"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
        "])\n",
        "\n",
        "print(\"Data transformations defined successfully.\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data transformations defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3c2bce"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 3, I will now load the FashionMNIST training and test datasets using `torchvision.datasets.FashionMNIST`. This involves specifying `train=True` for the training set and `train=False` for the test set, applying the defined `transform`, and setting `download=True` to ensure the datasets are available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c1696d6",
        "outputId": "c487642f-c296-4135-b1e3-ec612c04e1b2"
      },
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(f\"FashionMNIST training dataset loaded with {len(train_dataset)} samples.\")\n",
        "print(f\"FashionMNIST test dataset loaded with {len(test_dataset)} samples.\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26.4M/26.4M [00:02<00:00, 12.5MB/s]\n",
            "100%|| 29.5k/29.5k [00:00<00:00, 211kB/s]\n",
            "100%|| 4.42M/4.42M [00:01<00:00, 3.94MB/s]\n",
            "100%|| 5.15k/5.15k [00:00<00:00, 8.74MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionMNIST training dataset loaded with 60000 samples.\n",
            "FashionMNIST test dataset loaded with 10000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d42afff"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 4, I will now create `DataLoader` instances for both the training and test sets, specifying a `batch_size` and enabling shuffling for the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "572a2c33",
        "outputId": "1c238c7d-57ab-491c-d851-2db662555f13"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Training DataLoader created with batch size {batch_size}.\")\n",
        "print(f\"Test DataLoader created with batch size {batch_size}.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataLoader created with batch size 64.\n",
            "Test DataLoader created with batch size 64.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b0a210c"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 5, I will now define a Convolutional Neural Network (CNN) class, inheriting from `nn.Module`. This class will include at least two convolutional layers, activation functions, pooling layers, fully connected layers, and a `forward` method that handles the flattening of convolutional outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ea0d11c",
        "outputId": "61b93f59-1c89-466b-e1d2-9233e68ebd77"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second convolutional block\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        # The input size to the first FC layer depends on the output size of the last pooling layer.\n",
        "        # For a 28x28 input image: (28/2)/2 = 7\n",
        "        # So, it's 64 channels * 7 * 7 spatial dimensions\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10) # 10 classes for FashionMNIST\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv -> ReLU -> Pool 1\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.pool1(out)\n",
        "\n",
        "        # Conv -> ReLU -> Pool 2\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.pool2(out)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        out = out.view(out.size(0), -1) # Flatten all dimensions except batch size\n",
        "\n",
        "        # Fully connected layers\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "print(\"CNN class defined successfully.\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN class defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93ac8e0"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 6, I will now instantiate the CNN model and move it to a GPU if available. This involves creating an instance of the `CNN` class and checking for CUDA availability to set the device.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ef1ab5",
        "outputId": "218b5201-d5c9-49d1-a027-ff131e596c27"
      },
      "source": [
        "model_cnn = CNN()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_cnn.to(device)\n",
        "\n",
        "print(f\"CNN model instantiated and moved to {device} successfully.\")\n",
        "print(model_cnn)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN model instantiated and moved to cuda successfully.\n",
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad5f11eb"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 7, I will now define the loss function, `nn.CrossEntropyLoss`, suitable for multi-class classification, and an `optim.Adam` optimizer, passing the `model_cnn`'s parameters and a learning rate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04fe433",
        "outputId": "00063a06-4e0d-4e4a-ccf3-bc181ccb0a53"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function (CrossEntropyLoss) and optimizer (Adam) defined successfully.\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (CrossEntropyLoss) and optimizer (Adam) defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a04f9ed"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 8, I will now implement the complete training loop. This involves iterating through epochs, processing data in batches, moving data to the device, performing forward passes, calculating loss, zeroing gradients, backpropagating, and updating model parameters, finally printing the loss for each epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "050127b1",
        "outputId": "afa9a145-0586-4264-c455-443490cee990"
      },
      "source": [
        "num_epochs = 5\n",
        "\n",
        "print(\"Starting CNN training loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_cnn.train() # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print loss for every epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "print(\"CNN training loop completed.\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN training loop...\n",
            "Epoch [1/5], Loss: 0.4299\n",
            "Epoch [2/5], Loss: 0.2737\n",
            "Epoch [3/5], Loss: 0.2281\n",
            "Epoch [4/5], Loss: 0.1952\n",
            "Epoch [5/5], Loss: 0.1704\n",
            "CNN training loop completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6dda72d"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction 9, I will now implement an evaluation loop for the trained CNN model on the test set. This involves setting the model to evaluation mode, disabling gradient calculations, iterating through the test DataLoader, performing forward passes, calculating predictions, and finally computing and printing the test accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68eb4a56",
        "outputId": "85d65282-7adb-49b0-f0fe-e5afdefd0a7f"
      },
      "source": [
        "model_cnn.eval() # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model_cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # Get the index of the max log-probability\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the {total} test images: {accuracy:.2f}%')\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 91.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94fd4e3b"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the key PyTorch concepts covered and suggest next steps for further learning and exploration in areas like CNNs, RNNs, and advanced architectures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac1ee323"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "The task successfully demonstrated the creation, manipulation, and fundamental operations of Tensors using PyTorch, along with key concepts for building and training neural networks.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Tensor Fundamentals:** Tensors were successfully created from various sources (Python lists, NumPy arrays) and with specific initializations (`torch.empty`, `torch.zeros`, `torch.ones`, `torch.rand`, `torch.randn`). Their attributes (shape, data type, device) were inspected, and basic operations like reshaping, slicing, element-wise arithmetic, matrix multiplication, and transposition were performed.\n",
        "*   **Automatic Differentiation (`autograd`):** The core mechanism of `autograd` was explored by setting `requires_grad=True` for a tensor, building a computational graph, and computing gradients using `backward()`. Gradient accumulation and resetting with `zero_()` were demonstrated, along with disabling gradient tracking using `torch.no_grad()` and `detach()`.\n",
        "*   **Neural Network Construction (`nn.Module`):** A simple neural network was defined by subclassing `torch.nn.Module`, incorporating `Linear` layers, and implementing a `forward` method. The model's architecture was inspected, and a forward pass was successfully executed with dummy input.\n",
        "*   **Loss Functions and Optimizers:** Essential components for training, `nn.MSELoss` (for regression) and `nn.CrossEntropyLoss` (for classification) were instantiated. Common optimizers, `optim.SGD` and `optim.Adam`, were also successfully set up.\n",
        "*   **Data Handling (`Dataset` and `DataLoader`):** A custom `Dataset` class was created to encapsulate dummy features and labels. The `DataLoader` was then used to efficiently batch and shuffle this data, demonstrating batch iteration with correct tensor shapes.\n",
        "*   **Training Loop Implementation:** A complete training loop was implemented, integrating a defined `NeuralNetwork` model, a `BCEWithLogitsLoss` loss function, and an `Adam` optimizer. Over 10 epochs, the training loss decreased from approximately 0.7053 to 0.6397, indicating the model was learning.\n",
        "*   **Model Persistence:** The process of saving a model's state dictionary (`torch.save(model.state_dict(), ...)`) and loading it into a new model instance (`loaded_model.load_state_dict(torch.load(...))`) was successfully demonstrated. Outputs from the original and loaded models were verified to be identical.\n",
        "*   **Practical Application (Image Classification):** All learned concepts were integrated into a practical image classification task on the FashionMNIST dataset. A Convolutional Neural Network (CNN) was built, trained for 5 epochs (with training loss decreasing from ~0.4299 to ~0.1704), and achieved a test accuracy of **91.25%**.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Deepen Understanding of `autograd`:** Explore more complex computational graphs, custom `autograd.Function` implementations, and interactions with control flow to gain a more advanced understanding of gradient computation.\n",
        "*   **Explore Advanced Architectures:** Extend the practical application by implementing more complex CNN architectures (e.g., ResNet, VGG) or venturing into Recurrent Neural Networks (RNNs) for sequential data processing, and Transformer networks for state-of-the-art models.\n"
      ]
    }
  ]
}